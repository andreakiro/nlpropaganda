\pdfoutput=1
\documentclass[11pt]{article}

% Final version generation
% \usepackage[review]{acl}
\usepackage[]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% Latin characters
\usepackage[T1]{fontenc}

% UTF8 Encoding 
\usepackage[utf8]{inputenc}

% Space saver
\usepackage{microtype}

\title{
Language Model, RoBERTa and T5 implementations \\ 
for Detection of Propaganda Techniques in News Articles.\\
\vspace{0.2cm}
\small Natural Language Processing Project Proposal, Fall 2021
}

\author{
Antoine Basseto,
Giacomo Camposampiero 
\and Andrea Pinto \\         
ETH Zurich - Swiss Federal Institute of Technology \\ 
\texttt{\{abasseto, gcamposampie, pintoa\}@ethz.ch}
}

\begin{document}
\maketitle

\section{Introduction}

The proliferation of online misinformation has led to a significant amount of research into the automatic detection of fake news \cite{fakenews}. However, most of the efforts have been concentrated on whole-document classification \cite{rashkin-etal-2017-truth} or analysis of the general patterns of online propaganda \cite{garimella2015, chatfield2015}, while little has been done so far in terms of fine-grained text analysis. This approach could complement existing techniques and allow the user to extract more informed and nuanced judgment on the piece being read.

In this context, \textit{Task 11 of SemEval-2020}\footnote{The official task webpage: \url{https://propaganda.qcri.org/semeval2020-task11/}} \cite{semeval} aims to bridge this gap, facilitating the development of models capable of spotting text fragments where a defined set of propaganda techniques are used. 
This shared task provides a well-annotated dataset of 536 news articles, which enables the participant to develop detection models that automatically spot a defined range of 14 propaganda techniques in written texts \cite{semeval}.

The focus of the task is broken down into two well-defined sub-tasks, namely \textit{(1) Span identification (SI)} to detect the text fragments representative of a propaganda technique in the news articles and \textit{(2) Technique classification (TC)} to detect the propaganda technique used in a given text span.


\section{Objectives and Goals}
The primary goal of this Natural Language Processing project is two-fold:
\begin{enumerate}
    \item To implement different models able to automatically detect the use of propaganda techniques in text snippets, accomplishing both the \textit{Span identification} and \textit{Technique classification} sub-tasks of the previously mentioned shared task. \textit{SI} consists of a binary sequence tagging task, whereas \textit{TC} consists of a multi-class classification problem \cite{semeval}.
    \item To compare the implemented models and draw conclusions on their performance through an error analysis for each of them.
\end{enumerate}

\noindent
Furthermore, probings of possible future improvement tracks could be considered.

\section{Implementation}
Because the shared task is already a closed topic, many professional teams have made their way and produced a paper with satisfactory results. \citet{semeval} summarizes these results and outlines the winning teams' implementations. A literature review of these results was initially carried out to acquire information about possible implementation to be studied in our work.

As a result, the literature review outlined three interesting architectures that could be implemented to fulfill Goal (1).
\begin{enumerate}
        \item A small self-trained language model to provide a baseline performance we can compare other models to. The model will be implemented using PyTorch \cite{NEURIPS2019_9015}.
        \item RoBERTa \cite{roberta}, a state-of-the-art pre-trained model based on the Transformer architecture; this model is particularly appealing as it has been used in most winning teams' ensembles \cite{aschern, morio-etal-2020-hitachi-semeval} with quite interesting results.
        \item T5 \cite{2020t5}, another state-of-the-art Transformer based architecture that uses a text-to-text approach, whose performances could lead to good prediction performances. This particular model was also suggested to be of interest by the \textit{aschern} team \cite{aschern}, who achieved top scores in both sub-tasks.
    \end{enumerate}

To achieve Goal (2), the comparison between models will be carried out based on their performance in the shared task, using the F1-score on the test dataset as proposed by the task's organizers \cite{semeval}. A more thorough error analysis will be done for each model, pointing out any pattern in their weaknesses and possible ways of improvement for future work.

\section{Milestones}
The main deadlines outlined by the project regulation are reported in the following list. 
\begin{itemize}
    \item Project Proposal submission, \textit{31/10/2021}
    \item Progress Report submission, \textit{15/12/2021}
    \item Final Paper submission, \textit{15/01/2021}
    \item Project Presentation, \textit{18/01/2021}
\end{itemize}
Other than these important milestones, the project group will also carry out weekly meeting in order to ensure a good communication and a regular project progress during the course of the semester. 

\section{Expected results}
Our team expects to be able to successfully implement all the three mentioned architecture and carry out an objective and complete error analysis on these models. Eventually, achieving good classification results on both \textit{SI} and \textit{TC} will be considered a great success, even if not the primary goal of this experience.

% To add references without citing in text
\nocite{}

% Entries custom bib
\bibliography{custom}
\bibliographystyle{acl_natbib}

% \appendix
% \section{Example Appendix}
% \label{sec:appendix}
% In case we need an appendix.

\end{document}